---
title: 'SSAFY CS 스터디: 이취컴 Chapter 2-4 정리'
sidebar_label: '이취컴 Chapter 2-4 정리'
eng_title: 'SSAFY CS Study: Chapter 2-4 Summary'
image: https://til.qriosity.dev/img/m_banner_background.jpg
sidebar_position: 5
created_date: 2026-02-09
updated_date: 2026-02-09
---

# SSAFY CS 스터디: 이취컴 Chapter 2-4 정리

:::info Chapter 02 컴퓨터 구조 - 4 메모리

p.90~106

:::

<br />

:::caution ROM도 메인 메모리에요

메인 메모리 역할을 하는 저장장치에는 RAM과 ROM이 있지만, 보통 메인 메모리라고 하면 RAM을 의미한다.

:::

### RAM

CPU가 실행할 대상을 저장하는 부품이자, 휘발성 저장장치<br />
↔️ 보조기억장치: 보관할 대상을 저장하는 비휘발성 저장장치

RAM의 용량이 작으면 보조기억장치로부터 실행할 프로그램을 가지고 오는 일이 잦아져 실행시간이 길어지지만<br />
용량이 크면 많은 데이터를 미리 RAM에 올려둘 수 있기 때문에 많은 프로그램을 동시에 실행하는데 유리하다.

:::caution 무조건 다다익선은 아님

RAM이 필요 이상으로 커진다고 해도 반드시 컴퓨터 성능이 이에 비례하여 향상되는 것은 아니다.

:::

#### RAM의 뜻

Random Access Memory<br />
- 임의 접근: 임의의 위치에 곧장 접근 가능한 방식을 의미(= 직접 접근, direct access)
    - ↔️ 순차 접근: 특정 위치에 저장된 요소에 접근하기 위해 처음부터 순차적으로 접근하는 방식

#### RAM의 종류

##### 1. DRAM
시간이 지나면 저장된 데이터가 점차 사라지는 RAM<br />
데이터 소멸을 막기 위해 일정 주기로 데이터를 재활성화해야 함<br />
소비전력이 낮고, 저렴하고, 집적도가 높아 대용량 메모리 설계에 용이하기 때문에 일반적으로 사용한다.

##### 2. SRAM
시간이 지나도 저장된 데이터가 사라지지 않는 RAM(물론 휘발성이라 전원 나가면 데이터 소실됨)<br />
DRAM보다 빠르지만, 소비 전력 크고 비싸며, 집적도가 낮아 대용량보단 속도가 빨라야 하는 캐시 메모리에 사용된다.

##### 3. SDRAM
클럭 신호와 동기화된, 발전된 형태의 DRAM (SRAM + DRAM 합성어 아님 주의)<br />
클럭 타이밍에 CPU와 정보를 주고받을 수 있음<br />
= SDR SDRAM

##### 4. DDR SDRAM
대역폭을 넓혀 속도를 빠르게 만든 SDRAM<br />
SDRAM보다 전송 속도가 두 배 가량 빠름<br />
> *대역폭: 데이터를 주고받을 길의 너비*

:::info DDR 뒤에 붙는 숫자의 의미

DDR2 -> DDR의 2배, SDR의 4배<br />
DDR3 -> DDR2의 2배, SDR의 8배<br />
DDR4 -> DDR3의 2배, SDR의 16배<br />

:::

:::note 큐리의 홈서버 메모리는?

<p style={{fontSize:'1.5rem', fontWeight:'bold'}}>*DDR5*</p>

```sh {26}
qriosity@server:~$ sudo dmidecode -t memory
# dmidecode 3.5
Getting SMBIOS data from sysfs.
SMBIOS 3.5.0 present.

Handle 0x0010, DMI type 16, 23 bytes
Physical Memory Array
	Location: System Board Or Motherboard
	Use: System Memory
	Error Correction Type: None
	Maximum Capacity: 64 GB
	Error Information Handle: 0x000F
	Number Of Devices: 2

Handle 0x0013, DMI type 17, 92 bytes
Memory Device
	Array Handle: 0x0010
	Error Information Handle: 0x0012
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 32 GB
	Form Factor: SODIMM
	Set: None
	Locator: DIMM 0
	Bank Locator: P0 CHANNEL A
	Type: DDR5
	Type Detail: Synchronous Unbuffered (Unregistered)
    ...
```

:::

<br />

### 메모리에 바이트를 밀어 넣는 순서 - 빅 엔디안과 리틀 엔디안

현대 메모리는 데이터를 바이트 단위로 저장하고 관리<br />
메모리는 데이터를 CPU로부터 4바이트 또는 8바이트의 워드 단위로 받아들인다.<br />
이후, 여러 바이트로 구성된 데이터를 여러 주소에 나누어 저장한다.<br />
- Ex. 한 주소에 1바이트씩을 저장하는 메모리는 4바이트를 4개 주소에 걸쳐 저장

이 때, 연속된 바이트를 어떤 순서로 저장하는지에 따라 빅 엔디안과 리틀 엔디안으로 나뉜다.

### 빅 엔디안

낮은 번지의 주소에 상위 바이트부터 저장하는 방식<br />
메모리 값을 사람이 직접 읽거나, 디버깅 시 편리하다는 장점이 있다.

(이미지)

### 리틀 엔디안

낮은 번지의 주소에 하위 바이트부터 저장하는 방식<br />
메모리 값을 사람이 직접 읽기엔 불편하지만, 수치 계산이 편리하다.

(이미지)

### 바이 엔디안

빅 엔디안과 리틀 엔디안 중 하나를 선택할 수 있도록 설계된 컴퓨터 환경 방식

:::info MSB와 LSB

- MSB: 숫자의 크기에 가장 큰 영향을 미치는 비트
- LSB: 숫자의 크기에 가장 작은 영향을 미치는 비트

즉, 빅 엔디안은 MSB부터 저장하고, 리틀 엔디안은 LSB부터 저장한다.

:::

<br />

### 캐시 메모리

CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 그 사이에 두는 SRAM 기반의 저장장치

CPU가 메모리에 접근하는 속도는 CPU가 레지스터에 접근하는 속도보다 느리기 때문에,<br />
CPU와 메인 메모리 사이에 캐시 메모리를 두어 CPU가 자주 참조하는 데이터를 미리 저장해 둠으로써 성능을 향상시킨다.<br />
캐시 메모리의 크기 또한 CPU 성능에 영향을 미친다.

- L1: 코어와 가장 가까운 캐시 메모리
- L2: L1보다 크고 느린 캐시 메모리
- L3: L2보다 크고 느린 캐시 메모리

일반적으로 L1, L2는 코어 내부에, L3는 코어 외부에 위치한다.<br />
CPU는 L1 캐시부터 순차적으로 탐색하여 데이터를 찾는다.

#### 멀티코어 프로세서에서의 캐시 구조

멀티코어 CPU에서는 각 코어가 독립적인 L1, L2 캐시를 가지며, L3 캐시는 코어들이 공유한다.

(이미지)

#### 분리형 캐시

L1 캐시는 명령어만 저장하는 L1I와 데이터만 저장하는 L1D로 나뉘기도 한다.<br />
이러한 유형의 캐시 메모리를 **분리형 캐시**라고 한다.

#### 캐시 히트와 캐시 미스

캐시 메모리는 CPU가 사용할 법한 것을 저장한다.

- 캐시 히트: 캐시 메모리가 예측하여 저장한 데이터가 CPU에 의해 실제로 사용되는 경우
- 캐시 미스: 틀린 예측으로 인해 CPU가 메모리로부터 직접 데이터를 가져와야 하는 경우
- 캐시 적중률: 캐시가 히트되는 비율

범용적으로 사용되는 컴퓨터의 캐시 적중률은 85~85% 이상

#### 참조 지역성의 원리

CPU가 사용할 법한 데이터를 예측하는 방법?<br />
👉 참조 지역성의 원리에 따라 메모리로부터 가져올 데이터를 결정한다.

- 시간 지역성: CPU는 최근에 접근했던 메모리에 다시 접근하려는 경향이 있다.
    - Ex. 변수: 여러번 반복 접근하여 사용됨
- 공간 지역성: CPU는 접근한 메모리 근처에 다시 접근하려는 경향이 있다.
    - Ex. 배열: 순차 접근 여부에 따라 실행속도가 달라짐

#### 캐시 메모리의 쓰기 정책과 일관성

CPU가 캐시 메모리에 데이터를 쓸 땐, 캐시 메모리에 새롭게 쓰여진 데이터와 메모리 상의 데이터가 일관성을 유지해야 한다.

메모리 1000번지의 값 200을 캐싱해둔 상태에서, CPU가 200을 300으로 변경하고자 하는 경우
- 메모리만 300으로 바꿔버리면 캐시 참조 시 200이 읽히는 문제 발생

따라서 다음의 방식을 사용한다.
- 즉시 쓰기: 캐시 메모리와 메모리에 동시에 쓰는 방법
    - 장점: 메모리를 항상 최신으로 유지하여 일관성 깨짐을 방지할 수 있다.
		- 단점: 데이터를 쓸 때마다 메모리를 참조해야 함 -> 버스 사용 시간, 쓰기 시간 늘어남
- 지연 쓰기: 캐시에만 써두고, 추후 수정된 데이터를 메모리에 한 번에 반영하는 방법
    - 장점: 메모리 접근 횟수 줄어듦 -> 즉시 쓰기 방식에 비해 속도 빠름
		- 단점: 메모리와 캐시 간 일관성이 깨질 수도 있음

:::info 멀티코어 프로세서 구조에서의 캐시 일관성

좀 더 딥하게 가자면, 각 코어 내의 캐시 일관성까지 따져야 할 경우도 존재한다.<br />
*각 코어 내 L1, L2 캐시에 들은 값들이 동기화되어 있지 않다면...? 아앗...!*

![](https://velog.velcdn.com/images/qriosity/post/c0a9e969-2a2f-4ed8-8db2-c588791c09b2/image.png)

이를 위해 **캐시 일관성 프로토콜**이라는 것이 있다... 정도로 넘어가자.

:::

#### 결론: 캐싱이 지닌 양날의 검

캐시 메모리를 사용한다는 것은, 데이터 접근 측면에서 어느정도 빠른 성능을 보장할 수 있지만,<br />
동시에 데이터 일관성을 유지하기 위한 책임이 따른다.